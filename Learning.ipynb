{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# test megengine grad\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Tensor([2.], device=xpux:0)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from megengine import Tensor\n",
    "\n",
    "x = Tensor([3.])\n",
    "w = Tensor([2.])\n",
    "b = Tensor([-1.])\n",
    "y = w * x + b\n",
    "from megengine.autodiff import GradManager\n",
    "\n",
    "with GradManager() as gm:\n",
    "    gm.attach(x)\n",
    "    y = w * x + b\n",
    "    gm.backward(y)  # dy/dx = w\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Code for XOR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "[[1. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 1.]\n",
      " [1. 1.]]\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0.]\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "from megengine.data import DataLoader, RandomSampler\n",
    "import megengine\n",
    "import numpy as np\n",
    "from megengine.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class XOR_Dataset(Dataset):\n",
    "    def __init__(self, dataset_size=6000):\n",
    "        super(XOR_Dataset, self).__init__()\n",
    "        self.dataset_size = dataset_size\n",
    "        self.input_data = np.round(np.random.rand(self.dataset_size, 2)).astype(np.uint)  # (N,2)\n",
    "        self.label = self.input_data[..., 0] ^ self.input_data[..., 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_data[index].astype(np.float32), self.label[index].astype(np.float32)\n",
    "\n",
    "\n",
    "train_dataset = XOR_Dataset()\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(dataset=train_dataset, batch_size=50))\n",
    "test_dataset = XOR_Dataset()\n",
    "test_sampler = megengine.data.SequentialSampler(test_dataset, batch_size=50)\n",
    "test_dataloader = DataLoader(test_dataset,sampler=test_sampler)\n",
    "print(len(train_dataloader.dataset))\n",
    "for x, y in train_dataloader:\n",
    "    print(x)\n",
    "    print(type(x))\n",
    "    print(y)\n",
    "    print('-------')\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## network definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([0.578], device=xpux:0)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import megengine.functional as F\n",
    "import megengine.module as M\n",
    "\n",
    "\n",
    "class XOR_Net(M.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = M.Linear(2, 2)\n",
    "        self.fc2 = M.Linear(2, 1)\n",
    "        self.init_self()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.fc1(input))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    def init_self(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, M.Conv2d):\n",
    "                M.init.msra_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    fan_in, _ = M.init.calculate_fan_in_and_fan_out(m.weight)\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    M.init.uniform_(m.bias, -bound, bound)\n",
    "            elif isinstance(m, M.BatchNorm2d):\n",
    "                M.init.ones_(m.weight)\n",
    "                M.init.zeros_(m.bias)\n",
    "            elif isinstance(m, M.Linear):\n",
    "                M.init.msra_uniform_(m.weight, a=math.sqrt(5))\n",
    "                if m.bias is not None:\n",
    "                    fan_in, _ = M.init.calculate_fan_in_and_fan_out(m.weight)\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    M.init.uniform_(m.bias, -bound, bound)\n",
    "\n",
    "\n",
    "my_net = XOR_Net()\n",
    "\n",
    "print(my_net(megengine.Tensor([1, 1])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, train_loss = 0.701, train_acc = 0.489, val_acc = 0.492\n",
      "Epoch = 1, train_loss = 0.697, train_acc = 0.489, val_acc = 0.492\n",
      "Epoch = 2, train_loss = 0.695, train_acc = 0.325, val_acc = 0.244\n",
      "Epoch = 3, train_loss = 0.694, train_acc = 0.296, val_acc = 0.500\n",
      "Epoch = 4, train_loss = 0.693, train_acc = 0.508, val_acc = 0.500\n",
      "Epoch = 5, train_loss = 0.693, train_acc = 0.510, val_acc = 0.500\n",
      "Epoch = 6, train_loss = 0.693, train_acc = 0.726, val_acc = 0.752\n",
      "Epoch = 7, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 8, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 9, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 10, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 11, train_loss = 0.693, train_acc = 0.748, val_acc = 0.752\n",
      "Epoch = 12, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 13, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 14, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 15, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 16, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 17, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 18, train_loss = 0.693, train_acc = 0.729, val_acc = 0.752\n",
      "Epoch = 19, train_loss = 0.693, train_acc = 0.753, val_acc = 0.752\n",
      "Epoch = 20, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 21, train_loss = 0.693, train_acc = 0.718, val_acc = 0.752\n",
      "Epoch = 22, train_loss = 0.693, train_acc = 0.755, val_acc = 0.752\n",
      "Epoch = 23, train_loss = 0.693, train_acc = 0.685, val_acc = 0.752\n",
      "Epoch = 24, train_loss = 0.693, train_acc = 0.658, val_acc = 0.752\n",
      "Epoch = 25, train_loss = 0.693, train_acc = 0.733, val_acc = 0.752\n",
      "Epoch = 26, train_loss = 0.693, train_acc = 0.744, val_acc = 0.508\n",
      "Epoch = 27, train_loss = 0.693, train_acc = 0.606, val_acc = 0.508\n",
      "Epoch = 28, train_loss = 0.693, train_acc = 0.515, val_acc = 0.508\n",
      "Epoch = 29, train_loss = 0.693, train_acc = 0.552, val_acc = 0.508\n",
      "Epoch = 30, train_loss = 0.693, train_acc = 0.525, val_acc = 0.508\n",
      "Epoch = 31, train_loss = 0.693, train_acc = 0.503, val_acc = 0.508\n",
      "Epoch = 32, train_loss = 0.693, train_acc = 0.511, val_acc = 0.508\n",
      "Epoch = 33, train_loss = 0.693, train_acc = 0.458, val_acc = 0.508\n",
      "Epoch = 34, train_loss = 0.693, train_acc = 0.459, val_acc = 0.508\n",
      "Epoch = 35, train_loss = 0.693, train_acc = 0.458, val_acc = 0.508\n",
      "Epoch = 36, train_loss = 0.693, train_acc = 0.450, val_acc = 0.508\n",
      "Epoch = 37, train_loss = 0.693, train_acc = 0.496, val_acc = 0.508\n",
      "Epoch = 38, train_loss = 0.693, train_acc = 0.455, val_acc = 0.508\n",
      "Epoch = 39, train_loss = 0.693, train_acc = 0.306, val_acc = 0.508\n",
      "Epoch = 40, train_loss = 0.693, train_acc = 0.402, val_acc = 0.508\n",
      "Epoch = 41, train_loss = 0.693, train_acc = 0.380, val_acc = 0.508\n",
      "Epoch = 42, train_loss = 0.693, train_acc = 0.382, val_acc = 0.508\n",
      "Epoch = 43, train_loss = 0.693, train_acc = 0.421, val_acc = 0.508\n",
      "Epoch = 44, train_loss = 0.693, train_acc = 0.428, val_acc = 0.508\n",
      "Epoch = 45, train_loss = 0.693, train_acc = 0.437, val_acc = 0.256\n",
      "Epoch = 46, train_loss = 0.693, train_acc = 0.266, val_acc = 0.508\n",
      "Epoch = 47, train_loss = 0.693, train_acc = 0.334, val_acc = 0.508\n",
      "Epoch = 48, train_loss = 0.693, train_acc = 0.444, val_acc = 0.256\n",
      "Epoch = 49, train_loss = 0.693, train_acc = 0.267, val_acc = 0.256\n",
      "Epoch = 50, train_loss = 0.693, train_acc = 0.430, val_acc = 0.256\n",
      "Epoch = 51, train_loss = 0.693, train_acc = 0.380, val_acc = 0.256\n",
      "Epoch = 52, train_loss = 0.693, train_acc = 0.272, val_acc = 0.256\n",
      "Epoch = 53, train_loss = 0.693, train_acc = 0.431, val_acc = 0.256\n",
      "Epoch = 54, train_loss = 0.693, train_acc = 0.269, val_acc = 0.256\n",
      "Epoch = 55, train_loss = 0.693, train_acc = 0.290, val_acc = 0.256\n",
      "Epoch = 56, train_loss = 0.693, train_acc = 0.277, val_acc = 0.256\n",
      "Epoch = 57, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 58, train_loss = 0.693, train_acc = 0.328, val_acc = 0.256\n",
      "Epoch = 59, train_loss = 0.693, train_acc = 0.269, val_acc = 0.256\n",
      "Epoch = 60, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 61, train_loss = 0.693, train_acc = 0.276, val_acc = 0.256\n",
      "Epoch = 62, train_loss = 0.693, train_acc = 0.286, val_acc = 0.256\n",
      "Epoch = 63, train_loss = 0.693, train_acc = 0.278, val_acc = 0.256\n",
      "Epoch = 64, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 65, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 66, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 67, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 68, train_loss = 0.693, train_acc = 0.297, val_acc = 0.256\n",
      "Epoch = 69, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 70, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 71, train_loss = 0.693, train_acc = 0.268, val_acc = 0.256\n",
      "Epoch = 72, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 73, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 74, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 75, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 76, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 77, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 78, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 79, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 80, train_loss = 0.693, train_acc = 0.265, val_acc = 0.256\n",
      "Epoch = 81, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 82, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 83, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 84, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 85, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 86, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 87, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 88, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 89, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 90, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 91, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 92, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 93, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 94, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 95, train_loss = 0.693, train_acc = 0.265, val_acc = 0.256\n",
      "Epoch = 96, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 97, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 98, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 99, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 100, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 101, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 102, train_loss = 0.693, train_acc = 0.267, val_acc = 0.256\n",
      "Epoch = 103, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 104, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 105, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 106, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 107, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 108, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 109, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 110, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 111, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 112, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 113, train_loss = 0.693, train_acc = 0.274, val_acc = 0.256\n",
      "Epoch = 114, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 115, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 116, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 117, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 118, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 119, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 120, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 121, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 122, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 123, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 124, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 125, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 126, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 127, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 128, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 129, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 130, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 131, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 132, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 133, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 134, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 135, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 136, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 137, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 138, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 139, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 140, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 141, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 142, train_loss = 0.693, train_acc = 0.301, val_acc = 0.256\n",
      "Epoch = 143, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 144, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 145, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 146, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 147, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 148, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 149, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 150, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 151, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 152, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 153, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 154, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 155, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 156, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 157, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 158, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 159, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 160, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 161, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 162, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 163, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 164, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 165, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 166, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 167, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 168, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 169, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 170, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 171, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 172, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 173, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 174, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 175, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 176, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 177, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 178, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 179, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 180, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 181, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 182, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 183, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 184, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 185, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 186, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 187, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 188, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 189, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 190, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 191, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 192, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 193, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 194, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 195, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 196, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 197, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 198, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n",
      "Epoch = 199, train_loss = 0.693, train_acc = 0.264, val_acc = 0.256\n"
     ]
    }
   ],
   "source": [
    "from megengine.autodiff import GradManager\n",
    "import megengine.optimizer as optim\n",
    "\n",
    "gm = GradManager().attach(my_net.parameters())\n",
    "optimizer = optim.SGD(my_net.parameters(), lr=0.01)  # lr may vary with different model\n",
    "\n",
    "nums_epoch = 200\n",
    "for epoch in range(nums_epoch):\n",
    "    training_loss = 0\n",
    "    nums_train_correct, nums_train_example = 0, 0\n",
    "    nums_val_correct, nums_val_example = 0, 0\n",
    "\n",
    "    for step, (data, label) in enumerate(train_dataloader):\n",
    "    # for step, (data, label) in enumerate(train_dataset):\n",
    "        data = megengine.Tensor(data)\n",
    "        label = megengine.Tensor(label)\n",
    "\n",
    "        with gm:\n",
    "            score = my_net(data).flatten()\n",
    "            loss = F.nn.binary_cross_entropy(score, label, with_logits=False)\n",
    "            gm.backward(loss)\n",
    "            optimizer.step().clear_grad()\n",
    "\n",
    "        training_loss += loss.item() * len(data)\n",
    "\n",
    "        # pred = F.argmax(score, axis=1)\n",
    "        pred = F.round(score).flatten()\n",
    "        nums_train_correct += (pred == label).sum().item()\n",
    "        nums_train_example += len(data)\n",
    "\n",
    "    training_acc = nums_train_correct / nums_train_example\n",
    "    training_loss /= nums_train_example\n",
    "\n",
    "    for data, label in test_dataloader:\n",
    "        data = megengine.Tensor(data)\n",
    "        label = megengine.Tensor(label)\n",
    "        pred = F.round(my_net(data)).flatten()\n",
    "\n",
    "        nums_val_correct += (pred == label).sum().item()\n",
    "        nums_val_example += len(data)\n",
    "\n",
    "    val_acc = nums_val_correct / nums_val_example\n",
    "\n",
    "    print(f\"Epoch = {epoch}, \"\n",
    "          f\"train_loss = {training_loss:.3f}, \"\n",
    "          f\"train_acc = {training_acc:.3f}, \"\n",
    "          f\"val_acc = {val_acc:.3f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}